# Playground-S4E1
Binary Classification of Bank Churn Dataset

# Kaggle Playground Series: Binary Classification

## Overview
This repository contains the code for a machine learning project focused on binary classification as part of the Kaggle Playground Series. The project aims to predict a binary outcome using machine learning techniques on the provided dataset.

## Dataset
The dataset used for this project is from the Kaggle Playground Series. It contains :

The bank customer churn dataset is a commonly used dataset for predicting customer churn in the banking industry. It contains information on bank customers who either left the bank or continue to be a customer. The dataset includes the following attributes:

-Customer ID: A unique identifier for each customer

-Surname: The customer's surname or last name

-Credit Score: A numerical value representing the customer's credit score

-Geography: The country where the customer resides (France, Spain or Germany)

-Gender: The customer's gender (Male or Female)

-Age: The customer's age.

-Tenure: The number of years the customer has been with the bank

-Balance: The customer's account balance

-NumOfProducts: The number of bank products the customer uses (e.g., savings account, credit card)

-HasCrCard: Whether the customer has a credit card (1 = yes, 0 = no)

-IsActiveMember: Whether the customer is an active member (1 = yes, 0 = no)

-EstimatedSalary: The estimated salary of the customer

-Exited: Whether the customer has churned (1 = yes, 0 = no)

## Machine Learning Model
In this project, various machine learning algorithms were employed for binary classification. The primary steps include data preprocessing, feature engineering, model selection, hyperparameter tuning, and evaluation.

### Model Selection
The following machine learning algorithms were explored:
- Logistic Regression
- Decision Tree Classifier
- Random Forest Classifier
- HistGradientBoosting Classifier
- Light Gradient Boosting Classifier

### Evaluation Metrics
To assess the performance of the models, the following evaluation metrics were used:
- ROC-AUC Score

## Repository Structure
- `data/`: Contains the dataset used for training and testing.
- `notebooks/`: Contains Jupyter notebooks used for data exploration, preprocessing, modeling, and evaluation.
- `README.md`: This file, providing an overview of the project.



## Contributors
- [Shaibalini Kapuri](https://github.com/ShaibaliniKapuri)


